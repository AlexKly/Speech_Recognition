{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayers_Classifier:\n",
    "    \n",
    "    def __init__(self, num_neurons_in_layer, learning_rate, type_activation, epochs):\n",
    "        # Number of neurons in layers:\n",
    "        self.num_neurons_in_layer = num_neurons_in_layer\n",
    "        # Learning rate:\n",
    "        self.learning_rate = learning_rate\n",
    "        # Number of learing loops:\n",
    "        self.epochs = epochs\n",
    "        # Initialization activation fucntion:\n",
    "        if type_activation == 'sigmoid':\n",
    "            self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        elif type_activation == 'tanh':\n",
    "            self.activation_function = lambda x: 2 * scipy.special.expit(2 * x) - 1\n",
    "            \n",
    "        # Number layers:\n",
    "        self.num_layers = len(num_neurons_in_layer)\n",
    "        # Initialization weights:\n",
    "        self.Weigths = []\n",
    "        \n",
    "        for layer in range(self.num_layers - 1):\n",
    "            next_layer = num_neurons_in_layer[layer + 1]\n",
    "            pres_layer = num_neurons_in_layer[layer] + 1\n",
    "            weights_layer = np.random.randn(next_layer, pres_layer) * np.sqrt(2 / (pres_layer + next_layer))\n",
    "            self.Weigths.append(weights_layer)\n",
    "        \n",
    "            \n",
    "    def fit_classifier(self, inputLayer_values, labels):\n",
    "        for epoch in range(self.epochs):\n",
    "            # Forward propagation:\n",
    "            Input_values = [inputLayer_values]\n",
    "            Output_values = [inputLayer_values]\n",
    "            for layer in range(self.num_layers - 1):\n",
    "                outputs = Output_values[layer]\n",
    "                outputs = np.insert(outputs, 0, 0.1)\n",
    "                new_inputs = np.dot(self.Weigths[layer], outputs)\n",
    "                new_outputs = self.activation_function(new_inputs)\n",
    "                Input_values.append(new_inputs)\n",
    "                Output_values.append(new_outputs)\n",
    "                \n",
    "            # Get errors:\n",
    "            Layers_errors = []\n",
    "            for layer in range(self.num_layers - 1):\n",
    "                if layer == 0:\n",
    "                    error = (labels - Output_values[-1]) ** 2\n",
    "                elif layer == 1:\n",
    "                    error = np.dot(self.Weigths[-layer].T, Layers_errors[layer - 1])\n",
    "                    error = error[1:]\n",
    "                else:\n",
    "                    w = self.Weigths[-layer]\n",
    "                    w = w[:, 1:]\n",
    "                    error = np.dot(w.T, Layers_errors[layer])\n",
    "                Layers_errors.append(error)\n",
    "            \n",
    "            # Back propagation:\n",
    "            for layer in range(self.num_layers - 1):\n",
    "                self.Weigths[-layer - 1] += self.learning_rate * np.dot(Layers_errors[-layer - 1] * Output_values[-layer - 1] * (1.0 - Output_values[-layer - 1]), Output_values[-layer - 2]) \n",
    "                \n",
    "        return Output_values\n",
    "            \n",
    "        def predict():\n",
    "            pass\n",
    "            \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.15899235,  0.33879671, -0.36560513, -0.32430479],\n",
       "        [-0.69066832,  1.04163806,  0.09870995,  0.46915449],\n",
       "        [-0.5470375 , -0.15556082,  0.44318167,  0.94207966]]),\n",
       " array([[-0.63547848,  1.0920336 , -0.51356772, -0.68667764],\n",
       "        [ 0.25440624,  0.15072858, -0.57039819, -0.44479176],\n",
       "        [-0.76845306, -0.12477371,  0.38021404,  1.00231116]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultiLayers_Classifier([3, 3, 3], 0.1, 'sigmoid', 10)\n",
    "\n",
    "clf.Weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([10. , 10.5, 11. ]),\n",
       " array([0.02416553, 0.99999995, 0.99999892]),\n",
       " array([0.27485225, 0.32764732, 0.82777288])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.linspace(10, 11, 3)\n",
    "labels = np.zeros((3))\n",
    "outputs = clf.fit_classifier(test, labels)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = clf.Weigths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87259408, -0.15868453, -0.40503127],\n",
       "       [ 0.68210542, -0.17971387,  0.26759963],\n",
       "       [ 0.53437178, -0.33482412, -1.5894674 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
